import numpy as np
from sklearn.model_selection import train_test_split, KFold
import matplotlib.pyplot as plt
import sklearn.linear_model as skl
from sklearn.metrics import mean_squared_error, r2_score
from imageio.v2 import imread


def create_X(x, y, n ):
    if len(x.shape) > 1:
        x = np.ravel(x)
        y = np.ravel(y)

    N = len(x)
    l = int((n+1)*(n+2)/2)		# Number of elements in beta
    X = np.ones((N,l))

    for i in range(1,n+1):
        q = int((i)*(i+1)/2)
        for k in range(i+1):
            X[:,q+k] = (x**(i-k))*(y**k)

    return X


# Load the terrain
file_path = 'C:/Users/krist/Downloads/sognsvann.tif'
terrain = imread(file_path)
N = 1000
m = 10  # polynomial order
terrain = terrain[:N, :N]

x = np.linspace(0, 1, np.shape(terrain)[0])
y = np.linspace(0, 1, np.shape(terrain)[1])
x_mesh, y_mesh = np.meshgrid(x, y)

z = terrain.flatten()

polynomial = 9
k = 10
kfold = KFold(n_splits=k)

error = np.zeros(polynomial)
bias = np.zeros(polynomial)
variance = np.zeros(polynomial)
r2_scores = np.zeros(polynomial)
polydegree = np.zeros(polynomial)

# Perform the cross-validation to estimate MSE and R2
scores_KFold = np.zeros((polynomial, k))

for p in range(1, polynomial + 1):
    j = 0
    mse_values = []
    r2_values = []

    for train_inds, test_inds in kfold.split(x):
        xtrain = x[train_inds]
        ytrain = y[train_inds]

        # Create design matrix
        X = create_X(xtrain, ytrain, p)

        ztrain = z[train_inds]

        clf = skl.LinearRegression().fit(X, ztrain)

        xtest = x[test_inds]
        ytest = y[test_inds]
        # Create test design matrix
        Xtest = create_X(xtest, ytest, p)

        ztest = z[test_inds]

        z_pred = clf.predict(Xtest)

        mse = mean_squared_error(ztest, z_pred)
        r2 = r2_score(ztest, z_pred)

        mse_values.append(mse)
        r2_values.append(r2)

    error[p-1] = np.mean(mse_values)
    r2_scores[p-1] = np.mean(r2_values)
    bias[p-1] = np.mean((z[test_inds] - np.mean(z_pred)) ** 2)
    variance[p-1] = np.mean(np.var(z_pred))
    polydegree[p-1] = p

plt.plot(polydegree, error, label='MSE')
plt.plot(polydegree, r2_scores, label='R2 Score')
plt.plot(polydegree, bias, label='Bias')
plt.plot(polydegree, variance, label='Variance')
plt.xlabel("Polynomial degree")
plt.ylabel("Error")
plt.title(f"{k}-fold Cross Validation")
plt.legend()
plt.show()